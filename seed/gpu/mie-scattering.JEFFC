#include"mie-scattering.h"
#include"bessel.h"
#include"complex.h"
#include"cuda_setting.h"
#include"cuda_tools.h"
#include"physics_constants.h"
using namespace libjeff;

namespace libjeff{
  __host__ void mie_cal_mie_coeff(int max_order,int num_ka_pair,double* ka,complex* ref_index,complex* mie_coeff_an, complex* mie_coeff_bn){
    //required memory to 8* num_ka + 16* num_ka + 2*16*(order + 1)*num_ka + 16*num_ka + 16*(order + 1)*num_ka + 4*8*(order + 1)*num_ka + "small amount of memory in each thread for temporary storage"
    double *ka_bessel_ratio, *ka_neumann_ratio;
    double *besselj, *besselk;
    
    complex *nka_bessel_ratio, *nka;
    
    cudaMalloc((void**) &ka_bessel_ratio, num_ka_pair*(max_order+1)*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMalloc((void**) &besselj, num_ka_pair*(max_order+1)*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    int numthreads = cuda_setting::get_numthreads();
    dim3 grid;
    grid.x = (int) ceil((double) num_ka_pair/numthreads);
    g_bessel_riccati_besselj<<<grid,numthreads>>>(num_ka_pair,max_order,ka,ka_bessel_ratio,besselj);
    
    cudaMalloc((void**) &ka_neumann_ratio, num_ka_pair*(max_order+1)*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMalloc((void**) &besselk, num_ka_pair*(max_order+1)*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    g_bessel_riccati_besselk<<<grid,numthreads>>>(num_ka_pair,max_order,ka,ka_neumann_ratio,besselk);
    
    cudaMalloc((void**) &nka_bessel_ratio, num_ka_pair*(max_order+1)*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMalloc((void**) &nka, num_ka_pair*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cuda_multiply<<<grid,numthreads>>>(num_ka_pair,ref_index,ka,nka);
    g_bessel_riccati_besselj_ratio<<<grid,numthreads>>>(num_ka_pair,max_order,nka,nka_bessel_ratio);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    
    //Calculating the mie coefficient an's and bn's from the bessel and neumann function
    grid.x = (int) ceil(((double) num_ka_pair*(max_order+1)*2)/numthreads);
    g_mie_bessel_to_mie_coeff<<<grid,numthreads>>>(max_order,num_ka_pair,ka,nka,ref_index,besselj,besselk,ka_bessel_ratio,ka_neumann_ratio,nka_bessel_ratio,mie_coeff_an,mie_coeff_bn);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << "@g_mie_bessel_to_mie_coeff@mie-scattering-cuda with numBlocks, num_ka_pair, max_order" << grid.x << " " << num_ka_pair << " " << max_order << endl;
    
    cudaFree(besselj);
    cudaFree(besselk);
    cudaFree(nka);
    cudaFree(ka_bessel_ratio);
    cudaFree(ka_neumann_ratio);
    cudaFree(nka_bessel_ratio);
  }
  
  __host__ void mie_cal_extinction_cross_section(int max_order,int num_fre,int num_size,double* fre,complex* ref_index, double *size, double* sigma){
    //Assuming all input pointers points to host memory
    double *ka, *d_ka;
    complex *h_ref_index, *d_ref_index;
    
    ka = new double [num_fre*num_size];
    h_ref_index = new complex [num_fre*num_size];
    int i;
    int j;
    for(i=0;i<num_fre;i++){
      for(j=0;j<num_size;j++){
	ka[i*num_size+j] = 2*pi*fre[i]*size[j]/phys_c;
	h_ref_index[i*num_size+j] = ref_index[i];
      }
    }
    
    cudaMalloc((void**) &d_ka, num_fre*num_size*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMemcpy(d_ka,ka,num_fre*num_size*sizeof(double),cudaMemcpyHostToDevice);
    delete [] ka;
    cudaMalloc((void**) &d_ref_index, num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMemcpy(d_ref_index,h_ref_index,num_fre*num_size*sizeof(complex),cudaMemcpyHostToDevice);
    delete [] h_ref_index;
    
    complex *an, *bn;
    
    cudaMalloc((void**) &an, (max_order + 1)*num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMalloc((void**) &bn, (max_order + 1)*num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    mie_cal_mie_coeff(max_order,num_fre*num_size,d_ka,d_ref_index,an,bn);
    cudaFree(d_ref_index);
    
    double *d_sigma;
    cudaMalloc((void**) &d_sigma, num_fre*num_size*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    double *d_fre;
    cudaMalloc((void**) &d_fre, num_fre*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMemcpy(d_fre,fre,num_fre*sizeof(double),cudaMemcpyHostToDevice);
    mie_coeff_to_extinction_cross_section(max_order,num_fre,num_size,d_fre,d_ka,an,bn,d_sigma);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaFree(d_ka);
    cudaFree(d_fre);
    cudaFree(an);
    cudaFree(bn);
    
    cudaMemcpy(sigma,d_sigma,num_fre*num_size*sizeof(double),cudaMemcpyDeviceToHost);
    cudaFree(d_sigma);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
  }
  
  __host__ void mie_cal_extinction_and_backscattering_cross_section(int max_order,int num_fre,int num_size,double* fre,complex* ref_index, double *size, double* sigma_ext,double *sigma_back){
    //Assuming all input pointers points to host memory
    double *ka, *d_ka;
    complex *h_ref_index, *d_ref_index;
    
    ka = new double [num_fre*num_size];
    h_ref_index = new complex [num_fre*num_size];
    int i;
    int j;
    for(i=0;i<num_fre;i++){
      for(j=0;j<num_size;j++){
	ka[i*num_size+j] = fre[i]*size[j];
	h_ref_index[i*num_size+j] = ref_index[i];
      }
    }
    
    cudaMalloc((void**) &d_ka, num_fre*num_size*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMemcpy(d_ka,ka,num_fre*num_size*sizeof(double),cudaMemcpyHostToDevice);
    delete [] ka;
    cudaMalloc((void**) &d_ref_index, num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMemcpy(d_ref_index,h_ref_index,num_fre*num_size*sizeof(complex),cudaMemcpyHostToDevice);
    delete [] h_ref_index;
    
    complex *an, *bn;
    
    cudaMalloc((void**) &an, (max_order + 1)*num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaMalloc((void**) &bn, (max_order + 1)*num_fre*num_size*sizeof(complex));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    mie_cal_mie_coeff(max_order,(num_fre*num_size),d_ka,d_ref_index,an,bn);
    cudaFree(d_ref_index);
    
    double *d_sigma;
    cudaMalloc((void**) &d_sigma, num_fre*num_size*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    double *d_fre;
    cudaMalloc((void**) &d_fre, num_fre*sizeof(double));
    cudaMemcpy(d_fre,fre,num_fre*sizeof(double),cudaMemcpyHostToDevice);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    mie_coeff_to_extinction_cross_section(max_order,num_fre,num_size,d_fre,d_ka,an,bn,d_sigma);
    cudaMemcpy(sigma_ext,d_sigma,num_fre*num_size*sizeof(double),cudaMemcpyDeviceToHost);
    cudaFree(d_sigma);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    
    double *d_sigma_b;
    cudaMalloc((void**) &d_sigma_b, num_fre*num_size*sizeof(double));
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    mie_coeff_to_backscattering_cross_section(max_order,num_fre,num_size,d_fre,d_ka,an,bn,d_sigma_b);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << endl;
    cudaFree(d_ka);
    cudaFree(d_fre);
    cudaFree(an);
    cudaFree(bn);
    cudaMemcpy(sigma_back,d_sigma_b,num_fre*num_size*sizeof(double),cudaMemcpyDeviceToHost);
    cudaFree(d_sigma_b);
  }
  
  __host__ void mie_coeff_to_extinction_cross_section(int max_order,int num_fre,int num_size,double* fre,double *ka,complex* an,complex* bn,double* sigma){
    int num_ka_pair = num_fre*num_size;
    int numthreads = cuda_setting::get_numthreads();
    dim3 grid;
    grid.x = (int) ceil((double) num_ka_pair*2/numthreads);
    mie_coeff_sum_up_for_ext<<<grid,numthreads>>>(max_order,num_fre*num_size,ka,an,bn);
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << "@mie_coeff_sum_up_for_ext@mie_coeff_to_extinction_cross_section_gpu@mie-scattering-cuda" << endl;
    grid.x =(int) ceil(((double) num_ka_pair)/numthreads);
    mie_coeff_sum_to_extinction<<<grid,numthreads>>>(max_order,num_fre,num_size,fre,an,bn,sigma);  
    if ( cudaSuccess != cudaPeekAtLastError() ) cout << "Failed. " << cudaGetErrorString(cudaGetLastError()) << "@mie_coeff_sum_to_extinction@mie_coeff_to_extinction_cross_section_gpu@mie-scattering-cuda" << endl;
  }
  
  __host__ void mie_coeff_to_backscattering_cross_section(int max_order,int num_fre,int num_size,double* fre,double *ka,complex* an,complex* bn,double* sigma){
    int num_ka_pair = num_fre*num_size;
    int numthreads = cuda_setting::get_numthreads();
    dim3 grid;
    grid.x = (int) ceil((double) num_ka_pair*2/numthreads);
    mie_coeff_sum_up_for_back<<<grid,numthreads>>>(max_order,num_fre*num_size,an,bn);
    grid.x =(int) ceil(((double) num_ka_pair)/numthreads);
    mie_coeff_sum_to_backscattering<<<grid,numthreads>>>(max_order,num_fre,num_size,fre,an,bn,sigma);
  }
  
  __host__ __device__ int mie_wiscombe(double max_ka){
    return ((int) ceil(2+max_ka+pow(max_ka,1./3.)));
  }
  
  __global__ void g_mie_bessel_to_mie_coeff(int max_order,int num_ka_pair,double* ka,complex* nka,complex* ref_index,double* besselj,double* besselk,double* ka_bessel_ratio,double* ka_neumann_ratio,complex* nka_bessel_ratio,complex* mie_coeff_an, complex* mie_coeff_bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    //memory order (from fastest): order -> ka
    int j = i/((max_order + 1)*num_ka_pair); //index for division of labour on an/bn
    int k = i%((max_order + 1)*num_ka_pair)/(max_order + 1); //ka index
    int n = i%(max_order + 1); //order index
    int m = i%((max_order + 1)*num_ka_pair); //memory index
    //Mie coefficient does not need order 0. They start from order 1.
    //Please skip all those order zero locations
    
    if(j < 2 && n > 0){
      complex cn, dn, dnm;
      dn = complex(1.,0.)/ka_bessel_ratio[m] - n/ka[k];
      dnm = complex(1.,0.)/nka_bessel_ratio[m] - complex(n*1.,0.)/nka[k];
      cn = complex(1.,0.)/ka_neumann_ratio[m] - n/ka[k];
      
      if(j==0){
	mie_coeff_an[m] = complex(1.,0.)/((ref_index[k]*cn - dnm)/(ref_index[k]*dn - dnm)*complex(0.,besselk[m]/besselj[m]) + 1.);
      }
      else{
	mie_coeff_bn[m] = complex(1.,0.)/((ref_index[k]*dnm - cn)/(ref_index[k]*dnm - dn)*complex(0.,besselk[m]/besselj[m]) + 1.);
      }
    }
  }
  
  __global__ void mie_coeff_sum_up_for_ext(int max_order,int num_ka_pair,complex* an,complex* bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i%num_ka_pair;
      
      int k;
      if(i < num_ka_pair){
	an[j*(max_order+1)] = 0.;
	for(k=1;k<=max_order;k++){
	  an[j*(max_order+1)] += (an[j*(max_order+1)+k])*(2*k + 1.);
	}
      }
      else{
	bn[j*(max_order+1)] = 0.;
	for(k=1;k<=max_order;k++){
	  bn[j*(max_order+1)] += (bn[j*(max_order+1)+k])*(2*k + 1.);
	}
      }
    }
  }
  __global__ void mie_coeff_sum_up_for_ext(int max_order,int num_ka_pair,double *ka,complex* an,complex* bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i%num_ka_pair;
      int sum_order=mie_wiscombe(ka[j]);
      
      if(sum_order>max_order){
	sum_order = max_order;
      }
      
      int k;
      if(i < num_ka_pair){
	an[j*(max_order+1)] = 0.;
	for(k=1;k<=sum_order;k++){
	  an[j*(max_order+1)] += (an[j*(max_order+1)+k])*(2*k + 1.);
	}
      }
      else{
	bn[j*(max_order+1)] = 0.;
	for(k=1;k<=sum_order;k++){
	  bn[j*(max_order+1)] += (bn[j*(max_order+1)+k])*(2*k + 1.);
	}
      }
    }
  }
  __global__ void mie_coeff_sum_up_for_ext(int max_order,int num_ka_pair,double *ka,complex* an,complex* bn,double *sum_an,double *sum_bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i%num_ka_pair;
      int sum_order=mie_wiscombe(ka[j]);
      
      if(sum_order>max_order){
	sum_order = max_order;
      }
      
      int k;
      if(i < num_ka_pair){
	sum_an[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_an[j] += (an[j*(max_order+1)+k].real())*(2*k + 1.);
	}
      }
      else{
	sum_bn[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_bn[j] += (bn[j*(max_order+1)+k].real())*(2*k + 1.);
	}
      }
    }
  }
  __global__ void mie_coeff_sum_up_for_sct(int max_order,int num_ka_pair,double *ka,complex* an,complex* bn,double *sum_an,double *sum_bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i%num_ka_pair;
      int sum_order=mie_wiscombe(ka[j]);
      
      if(sum_order>max_order){
	sum_order = max_order;
      }
      
      int k;
      if(i < num_ka_pair){
	sum_an[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_an[j] += (an[j*(max_order+1)+k].abs2())*(2*k + 1.);
	}
      }
      else{
	sum_bn[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_bn[j] += (bn[j*(max_order+1)+k].abs2())*(2*k + 1.);
	}
      }
    }
  }
  __global__ void mie_coeff_sum_up_for_abs(int max_order,int num_ka_pair,double *ka,complex* an,complex* bn,double *sum_an,double *sum_bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i%num_ka_pair;
      int sum_order=mie_wiscombe(ka[j]);
      
      if(sum_order>max_order){
	sum_order = max_order;
      }
      
      int k;
      if(i < num_ka_pair){
	sum_an[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_an[j] += (an[j*(max_order+1)+k].real() - an[j*(max_order+1)+k].abs2())*(2*k + 1.);
	}
      }
      else{
	sum_bn[j] = 0.;
	for(k=1;k<=sum_order;k++){
	  sum_bn[j] += (bn[j*(max_order+1)+k].real() - bn[j*(max_order+1)+k].abs2())*(2*k + 1.);
	}
      }
    }
  }
  
  __global__ void mie_coeff_sum_to_extinction(int max_order,int num_fre,int num_size,double* fre,complex *an,complex *bn,double *sigma){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_fre*num_size){
      //j is the frequency index
      int j = i/num_size;
      //k is the size index
      //int k = i%num_size;
      
      sigma[i] = (an[i*(max_order+1)].real() + bn[i*(max_order+1)].real())*pi*2./(4*pi*pi*fre[j]*fre[j])*phys_c*phys_c;
    }
  }
  
  __global__ void mie_coeff_sum_up_for_back(int max_order,int num_ka_pair,complex* an,complex* bn){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_ka_pair*2){
      int j = i/2;
      
      int k;
      if(i < num_ka_pair){
	an[j*(max_order+1)] = 0.;
	for(k=1;k<=max_order;k++){
	  if(k%2 == 0){
	    an[j*(max_order+1)] += an[j*(max_order+1)+k]*(2*k + 1.);
	  }
	  else{
	    an[j*(max_order+1)] -= an[j*(max_order+1)+k]*(2*k + 1.);
	  }
	}
      }
      else{
	bn[j*(max_order+1)] = 0.;
	for(k=1;k<=max_order;k++){
	  if(k%2 == 0){
	    bn[j*(max_order+1)] += (bn[j*(max_order+1)+k])*(2*k + 1.);
	  }
	  else{
	    bn[j*(max_order+1)] -= (bn[j*(max_order+1)+k])*(2*k + 1.);
	  }
	}
      }
    }
  }
  
  __global__ void mie_coeff_sum_to_backscattering(int max_order,int num_fre,int num_size,double* fre,complex *an,complex *bn,double *sigma){
    int i = blockDim.x*blockIdx.x + threadIdx.x;
    
    if(i < num_fre*num_size){
      //j is the frequency index
      int j = i/num_size;
      //k is the size index
      //int k = i%num_size;
      
      sigma[i] = (an[i*(max_order+1)] - bn[i*(max_order+1)]).abs2()/(4*fre[j]*fre[j]);
    }
  }
}
